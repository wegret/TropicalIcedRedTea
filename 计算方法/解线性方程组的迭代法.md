[TOC]



# 解线性方程组的迭代法

## 引入：为什么需要迭代法？

直接法解线性方程组，复杂度较高，空间复杂度是$O(n^2)$，计算量或达$O(n^3)$，很多时候会得到稀疏矩阵。迭代法的主要思想是，如何从解的某个近似值出发，通过构造一个无穷序列去逼近精确解的方法。（一般有限步内得不到精确解）。

简单来说，就是找一个初始的向量（可能是全零的，总之是一个初始值）

主要做法是
$$
AX=b\\
X=BX+g
$$
以一个方程组举例：
$$
\begin{cases}
8x_1 + 2x_2 - x_3 = 3 \\
3x_1 + 10x_2 + x_3 = -16 \\
-x_1 + 2x_2 + 20x_3 = 15
\end{cases}
$$
这个可以转换成：
$$
\begin{cases}
x_1 = \frac{3 - 2x_2 + x_3}{8} \\
x_2 = \frac{-16 - 3x_1 - x_3}{10} \\
x_3 = \frac{15 + x_1 - 2x_2}{20}
\end{cases}
$$
很明显，这就变成了一个$X=BX+g$的式子，迭代格式就是：
$$
\begin{cases}
x_1^{(k+1)} = \frac{3 - 2x_2^{(k)} + x_3^{(k)}}{8} \\
x_2^{(k+1)} = \frac{-16 - 3x_1^{(k)} - x_3^{(k)}}{10} \\
x_3^{(k+1)} = \frac{15 + x_1^{(k)} - 2x_2^{(k)}}{20}
\end{cases}
$$
放matlab跑一下，可以发现，这样经过反复迭代，就可以得到最后的解向量。但是很快就有问题：是只要转成$X=BX+g$这样就可以用迭代法求解吗？很明显结果并非如此，例如转成下列的方程：
$$
\begin{cases}
x_1 = 2x_2 + 5 \\
x_2 = 3x_1 + 5
\end{cases}
$$
这个迭代明显是不收敛的，初始值选的不好就找不到答案。后面会对什么样的方程组能够使用迭代法做出探讨。

## 一. 迭代法

对于给定的方程组$X=BX+g$, 用公式
$$
X^{(k+1)}=BX^{(k)}+g, k=0,1,2,...
$$
 代入求近似解的方法称为**迭代法**(或称为**一阶定常**迭代法, 这里$B$和$g$，都是固定的，与$k$无关，不会随着$k$变化而变化)。若 $lim_{k \to \infty} \mathbf{X}^{(k)}$ 存在（记为$X^*$，称此迭代法收敛，此时$X^*$ 就是该方程组的解，否则称此迭代法发散。

### 1    基本迭代法 / 雅可比（Jacobi）迭代法

要把给定$AX = b$转化成$X = BX + g$，通常将$A$分裂为$A = M – N$，其中$M$是可选择的可逆矩阵（必须可逆），且使得$MX=d$容易求解（比较好求逆），称$M$为**分裂矩阵**．
$$
AX=b\\
MX=NX+b\\
X=M^{-1}NX+M^{-1}b\\
$$
一个简单的构造，可以把$A=D-L-U$，这里$D$是对角线，$L$是对角线为0的下三角，$U$是对角线为0的上三角。（这里用减法是便于计算，后面把$D$放在左侧也是便于计算，因为对角部分的逆是比较好求的。）
$$
DX=(L+U)X+b\\
X=D^{-1} (L+U)X+D^{-1}b
$$
迭代矩阵：
$$
\begin{aligned}
B&=D^{-1}(L+U)\\
&=D^{-1}(D-A)\\
&=I-D^{-1}A
\end{aligned}
$$
迭代方程：
$$
X=BX+D^{-1}b
$$
缺点很明显：

① 至少需要2组$n$单元存储。

② 第$k$步已经获得的分量对后续分量的计算没有影响。

### 2    高斯-塞德尔（Gauss-Seidel）迭代法

雅可比迭代中，每次迭代仅与上一个结果有关，也就是$X^{(k)}$只和$X^{(k-1)}$有关系，和$X^{(k-2)},X^{(k-3)}...$都没有关系。这样其实很容易发现是可能发生问题的，例如，有可能出现循环节，导致继续迭代，精度上也没有提升。

高斯赛德尔迭代法，是对雅可比迭代法的一种改进。

以这个方程组：
$$
\begin{bmatrix}
 10 & 2 & -1\\
 3 & 8 & 2\\
 -1 & 2 & 10
\end{bmatrix}
X=
\begin{bmatrix}
6\\
13\\
10
\end{bmatrix}
$$
在高斯赛德尔迭代法中，先初始猜测一个答案，例如$x^{(0)}=\begin{bmatrix}
0\\
0\\
0
\end{bmatrix}$

然后进行第一轮迭代，先对$x_1$进行迭代，把$x_2^{(0)}=0,x_3^{(0)}=0$都代入第一行的方程$10x_1+2x_2-x_3=6$，算出来$x_1^{(1)}=\frac{6-2\times 0 +1\times 0}{10}=0.6$

然后对$x_2$进行迭代，很明显不能再用第一行的方程了，因为$x_1$已经用了，那就用第二行的。注意这时候当前的答案解是$x^*=\begin{bmatrix}
0.6\\
0\\
0
\end{bmatrix}$（$x_1$已经更新了），现在算出来$x_2^{(1)}=\frac{13-2*0.6}{8}=1.475$

然后同理继续计算$x_3^{(1)}=\frac{10+0.6-2\times 1.475}{10}=0.765$，

现在的$x^{(1)}=\begin{bmatrix}
0.6\\
1.475\\
0.765
\end{bmatrix}$，然后继续按照上述方法迭代即可。

很明显高斯赛德尔迭代法，只需要用$n$个单元存就行了，而且计算上很简单，比雅可比迭代法要好。

高斯赛德尔法的矩阵形式中，和雅可比的推导类似的。从上面我们知道，每次迭代，$x_i ^{(k+1)}$都和$x_i ^{(k)}$无关，也就是说，相当于这个行乘以列的时候，原先的值被消隐了，也就是对角线为0！因此我们知道了，推导矩阵方程的时候，这个迭代矩阵的对角线是0。

对于方程$AX=b$，我们把矩阵分解成$A=L+U+D$，这里的$L，U$是严格下三角、上三角，$D$是对角矩阵，然后整理成高斯赛德尔形式：
$$
(L+U+D)X=b\\
(L+D)X=-UX+b\\
\begin{aligned}
X&=-(L+D)^{-1}UX+(L+D)^{-1}b\\\
\end{aligned}
$$

### 3    超松弛法（SOR）：加速高斯赛德尔

超松弛法（Successive Over-Relaxation, SOR）是对高斯-塞德尔迭代法的一个改进，通过引入一个称为松弛因子（relaxation factor）的参数 $w$ 来加速收敛。在实际应用中，这种方法能够在很多情况下提高迭代的效率，尤其是在求解大型稀疏线性方程组时。

在朴素的高斯赛德尔中，我们在更新一个$x_i^{(k)}$的时候，是完全不在乎它原来的值的，也就是不在乎$x_i^{(k-1)}$。每次迭代，我们只考虑了其他变量的值和方程。而超松弛法加入了一个比例系数来更新。

先把朴素的高斯赛德尔算法中，每次的迭代记录为$x_i^{(k+1)}=f(x_1^{(k)},x_2^{(k)},...,x_n^{(k)})$（注意，这里的$f$的变量中没有$x_i^{(k)}$）。

然后可以写出SOR方法的更新公式：
$$
x_i^{(k+1)}=w\times f+(1-w)x_i^{(k)}
$$
这里的$w$就是所谓的松弛因子。通过对朴素高斯赛德尔的结果和原先$x_i^{(k)}$进行一个加权综合，来迭代得到新的$x_i^{(k+1)}$，这就是SOR方法。

在$w<1$时称低松弛，$w=1$是朴素高斯赛德尔算法（相当于又和原先的$x_i^{(k)}$完全无关了），$w>1$时被称为超松弛法。

在$w>1$的时候，很明显，原先的$x_i^{(k)}$的比例系数变成负数了，而新的结果的分量大于1！可以想象和弹弓一样，增加了新结果的分量，降低了低精度结果的影响，像弹弓一样，从而对计算结果进行加速。

很显然，这里的$w$的选取，对结果是影响比较大的。太大肯定会导致振荡，太小又太慢。

SOR方法的矩阵形式推导中，从前面我们已经知道了朴素的高斯赛德尔方法的方程是：
$$
\begin{aligned}
X&=-(L+D)^{-1}UX+(L+D)^{-1}b\\
&=(L+D)^{-1}(-UX+b)
\end{aligned}
$$
引入松弛因子，
$$
\begin{aligned}
X^{(k+1)}&=w[(L+D)^{-1}(-UX^{(k)}+b)]+(1-w)X^{(k)}\\
&=[-w(L+D)^{-1}U+(1-w)E]X^{(k)}+w(L+D)^{-1}b
\end{aligned}
$$


## 二. 迭代法的收敛性

从前面的三种算法可以看出来，不同的迭代法与不同的参数、不同的初始解，对迭代速度的影响都有可能有影响。能不能定量地算迭代几轮后的误差？

设迭代方程是$X^{(k+1)}=BX^{(k)}+g$，若$X^{*}$是精确解，那必有$X^{*}=BX^{*}+g$

相减一下可以得到误差
$$
X^{(k+1)}-X^{*}=B(X^{(k)}-X^{*})
$$
定义误差向量$\varepsilon ^{(k)}=X^{(k)}-X^{*}$

那么也会有$\varepsilon ^{(k)}=B \varepsilon ^{(k-1)}$，所以就会有$\varepsilon ^{(k)}=B^k \varepsilon ^{(0)}$

因此看出来，迭代矩阵$B$决定了迭代法的收敛性。如果收敛，也就是说$\lim_{k\rightarrow \infty} \varepsilon ^k=0$

那肯定就会有$\lim_{k\rightarrow \infty} B^k=0$

### 1    前置知识

#### 矩阵的范数

① 谱范数：$$||A||_2=\sigma_\max(A)$$，也就是最大奇异值，或者说$A^TA$最大特征值的平方根

② 列和的最大值

③ 行和的最大值

#### 矩阵序列的极限

**定理1**    $\lim_{k\rightarrow \infty}A^k=A \Leftrightarrow  \lim_{k\rightarrow\infty} ||A_k-A||=0$

这里的$||\cdot||$是任意一种算子范数。

**定理2**    $\lim A^k=0 \Leftrightarrow  \lim||A_k\mathbf{x}||=0$

**定理3**   
$$
\lim_{k\rightarrow \infty}B^k=0 \\
\Leftrightarrow& \rho(B)<1\\
\Leftrightarrow& \exist\space ||\cdot||_{\varepsilon}, \space ||B||_\varepsilon<1
$$
这里的$\rho (B)$，指的是矩阵$B$所有特征值的最大的绝对值，也就是谱半径。

### 2    一阶定常迭代法收敛性判断

在一阶定长迭代法中，收敛的**充要条件**是迭代矩阵$B$的谱半径，就是$\rho(B)<1$

但是如果在比较复杂的矩阵中，特征值是不好求的，但是还有个定理：
$$
\forall A\in R^{n\times n}, \forall 算子范数||\cdot||，\rho (A)\leq ||A||（对||A||_F也成立）
$$
也就是说，只要任意找一种算子范数，这种范数能小于1，就说明这个矩阵的谱半径小于1，也就是说这个迭代矩阵的算法是收敛的。

除此之外，如果找到某种范数小于1，设为$||B||=q<1$，还有更多的性质：

① $||x^*-x^{(k)}||\leq q^{k}||x^*-x^{(0)}||$

② $||x^*-x^{(k)}||\leq \frac{q}{1-q}||x^{(k)}-x^{(k-1)}||$

③ $$||x^*-x^{(k)}||\leq \frac{q^k}{1-q}||x^{(1)}-x^{(0)}||$$

**例：**考察这个方程组
$$
\begin{equation}
\begin{bmatrix}
8 & -3 & 2 \\
4 & 11 & -1 \\
2 & 1 & 4
\end{bmatrix}
\begin{bmatrix}
x_1 \\
x_2 \\
x_3
\end{bmatrix}=
\begin{bmatrix}
20 \\
33 \\
12
\end{bmatrix}
\end{equation}
$$
迭代矩阵：
$$
B&=&-\begin{bmatrix}
8 &  &  \\
 & 11 &  \\
 &  & 4
\end{bmatrix}^{-1}\begin{bmatrix}
8 & -3 & 2 \\
4 & 11 & -1 \\
2 & 1 & 4
\end{bmatrix}+E\\
&=&\begin{bmatrix}
0 & -\frac{3}{8} & \frac{1}{4} \\
\frac{4}{11} & 0 & -\frac{1}{11} \\
\frac{1}{2} & \frac{1}{4} & 0
\end{bmatrix}
$$
行范数小于1，收敛。

------

**例题**：给定方程组$AX=b$，其中
$$
A=\begin{bmatrix}
3 & 2\\
1 & 2
\end{bmatrix},
B=\begin{bmatrix}
3\\
-1
\end{bmatrix}
$$
用迭代公式
$$
X^{(k+1)}=X^{(k)}+a(b-AX^{(k)}),k=0,1,2...
$$
问$a$取什么数时，迭代收敛？取什么数时，收敛最快？

解：整理公式
$$
X^{(k+1)}=(E-aA)X^{(k)}+ab
$$

$$
B=(E-aA)=\begin{bmatrix}
1-3a & -2a\\
-a & 1-2a
\end{bmatrix}
$$

即$\rho(B)<1$时，迭代收敛。
$$
\begin{aligned}
\det (B-\lambda E)&=(2a+\lambda-1)(3a+\lambda-1)-2a^2\\
&=4a^2-5a+1+(5a-2)\lambda+\lambda^2\\
&=(\lambda +4a-1)(\lambda+a-1)
\end{aligned}
$$
故特征值为$\lambda_1=1-4a,\lambda_2 = 1-a$
$$
\rho(B)=\max\{|1-4a|,|1-a|\}<1
$$
故
$$
0<a<\frac 1 2
$$
收敛最快时，$\rho(B)$最小，此时$a=\frac 2 5$

------



### 3    收敛速度

渐进收敛速度$R(B)=-\ln\rho(B)$

### 4    复杂矩阵的收敛性分析

判断矩阵收敛，可以通过充分条件（计算范数）或者充要条件（计算特征值），但是这些对于大型矩阵都很麻烦。因此还有一些利用特殊性质来判断收敛的充分条件。

**定理**    若A为严格对角占优阵或不可约弱对角占优阵，则Jacobi迭代法和G-S迭代法收敛。

什么是严格对角占优矩阵？分为行对角占优和列对角占优，行对角占优，意思就是说每一行位于对角线上的元素的绝对值，比该行其他位置上所有元素的绝对值都大。即$|a_{ii}|>\sum_{j\neq i}|a_{ij}|$，列占优同理。

弱对角占优，就是把上述的$>$号换成大于等于$\geq$，但是要求至少有一个不等式严格成立。

什么是可约矩阵？如果能把$\{1,2,...,n\}$划分成两个集合$I$和$J$，使得所有$i\in I,j\in J$，都有$a_{ij}=0$，就是可约矩阵。

**定理**    若$A$和$2D-A$均为正定阵，则雅可比迭代法收敛；若$A$为正定针，则高斯赛德尔法收敛。

**定理**    若雅可比矩阵$B_J$非负，则下列关系有且仅有一个成立：

① $\rho (B_J)=\rho(B_G)=0$

② $0<\rho (B_G)<\rho (B_J)<1$

③ $\rho(B_J)=\rho(B_G)=1$

④ $1<\rho(B_J)<\rho(B_G)$

这个的意思是说，雅可比矩阵非负时，雅可比和高斯赛德尔两种方法的收敛性是一致的，并且此时高斯赛德尔要比雅可比收敛的更快。

> 迭代法收敛与否的判断与方程组中方程排列顺序有关

### 5    SOR法的收敛性

SOR的迭代矩阵是
$$
X^{(k+1)}=(D-wL)^{-1}[(1-w)D+wU]X^{(k)}+w(D-wL)^{-1}b\\
B_w=(D-wL)^{-1}[(1-w)D+wU]
$$
**定理**    若$a_{ii}\neq 0$，则有$\det (B_w)=(1-w)^n$，从而$\rho(B_w)\geq |1-w|$

**推论**    SOR法收敛的必要条件是$|1-w|<1$，即$0<w<2$

**定理**    $0<w<2$时，$A$若对称正定，则SOR法对任何初始向量都收敛。

**定理**    若$A$是对称正定的三对角矩阵，则$\rho (B_G)=[\rho(B_J)]^2<1$，且SOR法松弛因子$w$的最优选择是
$$
w_\text{opt}=\frac{2}{1+\sqrt{1-[\rho(B_J)]^2}}
$$
并且此时还有$\rho(B_\text{opt})=w_{\text{opt}}-1$

## 三. 共轭梯度法

共轭梯度法适用于系数矩阵$A$**对称正定**的情况下。这个问题的思路是，能不能把解方程变成一个优化问题？

对于方程
$$
AX=b\\
AX-b=0
$$
优化问题，通常就是找最小值，那这里的最小值是什么？可以考虑把$AX-b$这个函数积分起来，它的最小值就是导数为0的点，就是解。

构造一个二次函数
$$
\varphi(\mathbf{x})=\frac{1}{2}(A\mathbf{x},\mathbf{x})-(\mathbf{b},\mathbf{x})
$$
其实也就是
$$
\varphi(\mathbf{x})=\frac{1}{2}x^TAx-b^Tx
$$
**定理**    设$A$对称正定，则$x^*$为线性方程组解的充要条件是$x^*$满足
$$
\varphi(\mathbf{x}^*)=\min_{x\in R^n} \varphi(\mathbf{x})
$$

### 共轭梯度算法

共轭梯度法引入了残差向量$r$、搜索方向向量$p$、步长参数$\alpha$。残差就是和$r^{(k)}=b-Ax^{(k)}$，可以说残差越小，越接近真实解；搜索方向向量$p$通过残差和上次的方向来调整下次的方向，它是负梯度方向，确保每一次都沿着与之前的方向共轭的方向进行。

设计共轭梯度算法时，显然残差向量都可以通过$r^{(k)}=b-AX^{(k)}$得到，方向向量呢？我们希望方向向量能通过残差向量进行调整，一种朴素的想法是$p^{(k)}=r^{(k)}$，也就是说，直接沿着负梯度方向走。这样好吗？尽管每次都沿着梯度最大下降的方向走，但未必就最优，可能出现“之字形”。因此希望引入上次的方向，
$$
p^{(k+1)}=r^{(k+1)}+\beta_k p^{(k)}\\
\beta_k=\frac{( r^{(k+1)},r^{(k+1)})}{(r^{(k)},r^{(k)})}
$$
这个修正系数$\beta_k$使得新的方向与之前所有的方向都关于矩阵$A$共轭。也就是说，满足$\forall i\leq k,\space p^{(k+1)T}Ap^{(i)}=0$

在调整了残差、方向向量后，还需要调整步长，为了最小化沿着搜索方向$p^{(k)}$的目标函数需要找到使得$f(x^{(k)}+\alpha p^{(k)})$最小的$\alpha$。代入到原先函数里：
$$
f(x^{(k)}+\alpha p^{(k)})=\frac{1}{2}(x^{(k)}+\alpha p^{(k)})^TA (x^{(k)}+\alpha p^{(k)})-b^T(x^{(k)}+\alpha p^{(k)})
$$
直接对$\alpha$求导：
$$
\begin{aligned}
\frac{df}{d\alpha}&=\frac{d}{d\alpha}[\frac{1}{2}(x^{(k)}+\alpha p^{(k)})^TA (x^{(k)}+\alpha p^{(k)})-b^T(x^{(k)}+\alpha p^{(k)})]\\
&=A(x^{(k)}+\alpha p^{(k)})-b^T
\end{aligned}
$$


算法的流程如下：

任取一个初始解$x^{(0)}$，计算残差$r^{(0)}=-(Ax^{(0)}-b)$

初始的时候，梯度$p^{(0)}$和残差一致，$p^{(0)}=r^{(0)}$

然后根据上面两个东西，计算出下次的步长，也就是$\alpha_{0}=\frac{(r,r)}{(Ap,p)}$

因此，下一个$x^{(k+1)}$的公式直接由上次位置、方向和步长得到：
$$
x^{(k+1)}=x^{(k)}+\alpha_kp^{(k)}
$$
下次的残差
$$
r^{(k+1)}=r^{(k)}-\alpha_kAp^{(k)}
$$
这里的残差不直接计算$AX^{(k+1)}-b$（理论上在不考虑数值误差的时候应该是相同的），但是很明显，进行一次矩阵-向量乘法，非常不优。因此进行优化
$$
\begin{aligned}
r^{(k+1)}&=b-Ax^{(k+1)}\\
&=Ax^{(k)}+r^{(k)}-Ax^{(k+1)}\\
&=r^{(k)}-\alpha_k p^{(k)}
\end{aligned}
$$
在没有数值误差的情况下二者相同，但是在考虑进数值误差的情况下，这样计算只需要做线性的向量乘法，精度也比较高。

然后开始继续算步长，迭代出下一步的$x^{(k+1)}$，重复即可。

